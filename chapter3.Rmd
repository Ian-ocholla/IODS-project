# LOGISTIC REGRESSION ANALYSIS


In this exercise, we explore the use of **logistic regression analysis** on student achievement data in secondary education in two Portuguese schools. The data attribute include the student grades, demographic, social and school related features. The data was collected by using school reports and questionnaires. More information can be found in the [link](https://archive.ics.uci.edu/ml/datasets/Student+Performance)

Purpose of the analysis is to study the relationships between high/low alcohol consumption and students attributes. The _joined dataset_ used in the analysis exercise combines the two student alcohol consumption data sets. The following adjustment have been made;  

* 'alc_use is the average of 'Dalc' and 'Walc'  
* 'high_use' is true if 'alc_use' is higher than 2 and FALSE otherwise  

### 1. Load and describe the student alcohol consumption data 

```{r}
#set the work directory
setwd("C:/LocalData/ocholla/IODS-project")
#Load the data
alc<- read.csv("Data/pormath.csv", header = TRUE, stringsAsFactors = TRUE)
#print column names
colnames(alc)
#structure of the data
str(alc)
```

The dataset contains 370 observation of 51 variables, the variables are a mixture of integers, factors and logical data types

### 2. Analysis of student variables relationship with alcohol consumption.

Hypothesis on the four variables  

1. sex- male students consume higher alcohol compared to female students
2. studytime- low study time among the students increase the chances for high use of alcohol
3. famrel- Good quality family relationship reduces alcohol abuse.
4. goout- students who have a high tendency of going out with friends are prone to peer pressure which can easily lead to high alcohol consumption

**Distribution of alcohol consumption by gender**
```{r}
library(ggplot2)
g1<- ggplot(data= alc, aes(x = high_use, fill= sex))
#define the plot as a bar plot and draw it
g1+ geom_bar()+ ggtitle("Alcohol consumption across students by gender")
```

High proportion of male students indulge in high alcohol consumption compared to female students, whereas, more female student population consume low alcohol in comparison to the male student with low alcohol intake.

**Relationship between sex, quality family relationships and use of alcohol**
```{r}
#*summary statistics by sex and quality family relationships 
library(dplyr)
library(ggplot2)

#produce summary statistics by group
alc%>% group_by(sex, high_use)%>% summarise(count= n(), familytime=mean(famrel))
```

Four-fifth of all the female students have low alcohol consumption and they have higher mean in the quality of family relationship compared to female students who had high alcohol consumption. Similarly,  male students with high family relationship  had low alcohol consumption.  


**Relationship between sex and incidences of going out with alcohol consumption among the students** 
```{r}
#*failures
alc%>% group_by(sex, high_use)%>% summarise(count= n(), going_out=mean(goout))

```

In both genders, higher incidences of going out are associated with high consumption of alcohol

**Does high use of alcohol have a connection to study time?**
```{r}
#does high use of alcohol have a connection to romantic relationship?
a2<- ggplot(alc, aes(x= high_use, y = studytime, col= sex))
#define the plot as a boxplot and draw it
a2 + geom_boxplot()+ylab("Hours")+ggtitle("Student study hours by alcohol consumption and sex")
```

Among students with low alcohol consumption, the female students spent between 5 to 10 hours in their studies compared to male students who spent between 3-5 hours.

On the contrary, female students with high alcohol consumption spent exactly  5 hours for their studies while the make students spent 2 to 5 hours.

## 3. Fitting a logistics model

```{r}
#find the model with glm()
m<- glm(high_use~sex+studytime+famrel+goout, data = alc, family = "binomial")
#print out a summary of the model
summary(m)
```

From the model, the p-values for the four variables are statistically significant.
The output supports the hypothesis that gender, study time, going out and quality family relationship affects the student's alcohol consumption. The positive estimate value on the factor variable sex indicates likelihood of high use of alcohol among male students with reference to the female students


**Model coefficients**
```{r}
#Print out the coefficients of the model
coef(m)
```

Based on the regression coefficients, the odds of high use of alcohol increased with students being male and those with a high frequency of going out, while it decreased with in students who allocate more study time and have excellent family relationships. 
**Odd ratio** 
Odd ratio is  the ratio of expected "successes" to failures.Higher odds corresponds to a higher probability of success, with the value ranging from zero to infinity.

Transform the coefficients to odds ratios and transform it by exponentiation it to return it as a unit change in the predictor variable (*high_use*), holding all other predictor variables constant
```{r}
#compute odds ratios (OR)
OR<- coef(m)%>% exp
#compute confidence intervals (CI)
CI<- confint(m)%>% exp
#Print out te odds ratios with their CI
cbind(OR,CI)
```

With a confidence interval of 95%, the likelihood of high use of alcohol increased by  a factor of 2.21 and 2.19 when the student is of male gender and has high tendency of going going respectively. This means by that  On the contrary, the odds of high use of alcohol among students who allocate more study time and have good family relationships drops by -38.21% and -34.25%. Meaning in every one hour added in study time chances of high alcohol reduces by 38.21% while improvement of the family relationship reduces high use of alcohol by 34.25%.

**Predictive power of the model**
Exploring the predictive power of the logistic model, through a 2x2 cross tabulation of predictors versus the actual values. 

```{r}
#predict() the probability of high_use
probabilities <- predict(m, type = "response")
#add the predicted probabilities to alc
alc<- mutate(alc, probability= probabilities)
#use the probabilities to make a prediction of high_use
alc<- mutate(alc, prediction= probability>0.5)
#*see the first five original classes, predicted probabilities, 
select(alc, goout, famrel,studytime, sex, high_use,probability, prediction)%>% head(5)

```

The chances of high alcohol consumption declines when the student is female

**Confusion matrix (2x2) table**
```{r}
#tabulate the target variable versus the predictions 

table(high_use=alc$high_use, prediction=alc$prediction)
```
From the table, 230 low alcohol consumption was corrected while 29 were incorrectly predicted. on the other hand, 52 observation of high alcohol consumption were correctly predicted while 59 were wrongly predicted.

plotting the original *high_use* versus the predicted in alc
```{r}
#initialize a plot of 'high_use' versus 'probability' in alc
g<- ggplot(alc, aes(x = probability, y= high_use, col = prediction))
#define the geom as points and draw the plot
g+geom_point()

```

**Accuracy assessment through the confusion matrix**
```{r}
#tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction)%>% prop.table%>% addmargins
```

Approximately 19% and 36%  were inaccurately predicted for the false and true values respectively by the model.  
From the confusion matrix table, the accuracy of the prediction can be calculated through addition of True Negative and Positive (0.62 and 0.14) divided by the summation of both true and false values in both the original set (high_use) and prediction. we get that the prediction accuracy is 0.76, this is a high performance from the model compared to simple guessing strategies.    

### 4. Cross validation
This is a method of testing a predictive model on unseen data
split the data into training and testing data, 
whereby the training data is used to find the model 
while the test data is used to make prediction and evaluate the model performance

One round of cross validation involves  

1. partitioning a sample of data into complementary subsets  
2. Performing the analysis on one subset (the training set, larger)  
3. validating the analysis on the other subset (the testing set, smaller)  

This process is repeated so that eventually all of the data is used for both
training and testing.In CV, the value of a penalty(loss) function (mean prediction error) is computed on data not used for finding the model. A low CV value is an indication of a good model.

```{r}

```

**Cross validation using 10 K-folds**
```{r}
library(boot)
#define a loss function (average prediction error)
loss_func<- function(class, prob){
  n_wrong<-abs(class - prob)> 0.5
  mean(n_wrong)
}
#average number of wrong prediction
loss_func(class = alc$high_use, prob = alc$probability) 
cv<- cv.glm(data= alc, cost= loss_func, glmfit= m, K=10)
#average number of wrong predictions in the cross validation
cv$delta[1]
```

The model had a CV of 0.23 which is much better than that in the DataCamp.

**super bonus** 
Perform cross-validation to compare the performance of different logistic regression models (=different sets of predictors). Start with a very high number of predictors and explore the changes in the training and testing errors as you move to model with less predictors. draw a graph displaying the trends of both training and testing errors by the number of predictors in the model

```{r}
#find the model with glm()
summary(m0<- glm(high_use~G3+absences+traveltime+reason+famsize+sex+studytime+famrel+goout, data = alc, family = "binomial"))
summary(m1<- glm(high_use~absences+traveltime+reason+sex+studytime+famrel+goout, data = alc, family = "binomial"))
summary(m2<- glm(high_use~absences+traveltime+sex+studytime+famrel+goout, data = alc, family = "binomial"))
```


```{r}
date()
```

